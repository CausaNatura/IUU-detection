# -*- coding: utf-8 -*-
"""CNH3_unify_raster_layers_op.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1czBtA3-YkKYpGoGfSznxbRfpp28wN40z

# FIRST STEPS
"""

# install h3 into google collab
!pip install h3
!pip install shapely
!pip install rioxarray

# import libraries
import h3
import shapely
import rioxarray
import shapely.wkt
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
from shapely import wkt
from datetime import datetime
from shapely.wkt import dumps
from shapely.geometry import shape
from shapely.geometry import Polygon, Point

import os
os.chdir('OUTPUT')   ##CHANGE TO OUTPUT ROUTE 

##DEFINE FUNCTIONS
def h3_raster_statistics(raster, var, resolution, h3_id):
  """Produces an H3 grid from raster cells and populates it with cell statistics in a hex polygon.

  Args:
    raster: A Pandas DataFrame containing the raster data.
    var: The name of the variable to calculate statistics for.
    resolution: The resolution of the H3 grid.
    h3_id: The name of the column to store the H3 IDs in.

  Returns:
    A Pandas DataFrame containing the H3 grid and statistics for each hexagon.
  """

  # Filter the raster DF to only include the valid values.
  raster = raster[raster[var] > -3000]

  # find hexs containing the points
  raster[h3_id] = raster.apply(lambda x: h3.geo_to_h3(x.lat, x.lng, resolution), 1)

  # Calculate statistics for each hexagon.
  mean_values = raster.groupby(h3_id)[var].mean().to_frame(var + '_MEAN').reset_index()
  max_values = raster.groupby(h3_id)[var].max().to_frame(var + '_MAX').reset_index()
  min_values = raster.groupby(h3_id)[var].min().to_frame(var +'_MIN').reset_index()

  # Merge the statistics values to an out DF based on 'h3_id'
  raster_statistics = pd.merge(mean_values, max_values, on='h3_id', how='left') \
              .merge(min_values, on='h3_id', how='left')

  return raster_statistics

def h3_raster_mean(raster, var, resolution, h3_id):
  """Produces an H3 grid from raster cells and populates it with cell means in a hex polygon.

  Args:
    raster: A Pandas DataFrame containing the raster data.
    var: The name of the variable to calculate statistics for.
    resolution: The resolution of the H3 grid.
    h3_id: The name of the column to store the H3 IDs in.

  Returns:
    A Pandas DataFrame containing the H3 grid and mean values for each hexagon.
  """

  # Filter the raster DF to only include the valid values.
  raster = raster[raster[var] > -3000]

  # find hexs containing the points
  raster[h3_id] = raster.apply(lambda x: h3.geo_to_h3(x.lat, x.lng, resolution), 1)

  # Calculate mean values for each hexagon.
  raster_mean = raster.groupby(h3_id)[var].mean().to_frame(var + '_MEAN').reset_index()

  return raster_mean

"""# CAPAS CORREDOR"""

##DEFINE PATHS TO DATA FILES FOR EACH VARIABLE -- CORREDOR
## CHANGE TO INPUT FOLDER CONTAINING TIF FILES WITH CORREDOR EXTENT
variable_files = [
    ('bathymetry', 'LAYERS_INPUT_FOLDER/DEEP_ZERO_CORREDOR.tif'),
    ('DP_ENSENADABLANCA', 'LAYERS_INPUT_FOLDER/DIST_ENSENADABLANCA.tif'),
    ('DP_LA_PAZ', 'LAYERS_INPUT_FOLDER/DIST_LAPAZ.tif'),
    ('DP_LORETO','LAYERS_INPUT_FOLDER/DIST_LORETO.tif'),
    ('DP_LOSBARRILES', 'LAYERS_INPUT_FOLDER/DIST_LOSBARRILES.tif'),
    ('DP_LOSCABOS', 'LAYERS_INPUT_FOLDER/DIST_LOSCABOS.tif'),
    ('DP_MULEGE','LAYERS_INPUT_FOLDER/DIST_MULEGE.tif'),
    ('DP_NOPOLO','LAYERS_INPUT_FOLDER/DIST_NOPOLO.tif'),
    ('DP_PICHILINGUE','LAYERS_INPUT_FOLDER/DIST_PICHILINGUE.tif'),
    ('DP_PUERTOESCONDIDO','LAYERS_INPUT_FOLDER/DIST_PUERTOESCONDIDO.tif'),
    ('DP_PUNTAPRIETA','LAYERS_INPUT_FOLDER/DIST_PUNTAPRIETA.tif'),
    ('DP_SANJOSEDELCABO', 'LAYERS_INPUT_FOLDER/DIST_SANJOSEDELCABO.tif'),
    ('DP_SANJUANDELACOSTA','LAYERS_INPUT_FOLDER/DIST_SANJUANDELACOSTA.tif'),
]

res = 7
id = 'h3_id'
zone = 'corredor'

"""# PROCESS"""

##FOR BATHYMETRY
# Initialize raster_stats to None to merge the DataFrames
raster_stats = None

# Iterate through variable_files containing Bathymetry or statistics variables
# Only include the first item in the list to exclude DP - Distancia al Puerto or mean variables
for var, file_path in [variable_files[0]]:
    # Import *.tif raster to DataFrame.
    raster_df = (
        rioxarray.open_rasterio(file_path)
        .sel(band=1)
        .to_pandas()
        .stack()
        .reset_index()
        .rename(columns={'x': 'lng', 'y': 'lat', 0: var})
    )

    # Produce the H3 grid and populate it with the bathymetry statistics values.
    raster_statistics = h3_raster_statistics(raster_df, var, res, id)

    # If raster_stats is None, assign the first DataFrame; otherwise, merge
    if raster_stats is None:
        raster_stats = raster_statistics.copy()
    else:
        # Merge the DataFrame
        raster_stats = pd.merge(raster_statistics, raster_stats, on=id, how='left')
raster_stats.info()

##FOR PORT DISTANCE(S)
# Initialize raster_means to None to merge the DataFrames
raster_means = None

# Iterate through variable_files containing DP - Distancia al Puerto or mean variables
# Skip first item in dictionary to exclude Bathymetry or statistics layers
for var, file_path in variable_files[1:]:
    # Import *.tif raster to DataFrame.
    raster_df = (
        rioxarray.open_rasterio(file_path)
        .sel(band=1)
        .to_pandas()
        .stack()
        .reset_index()
        .rename(columns={'x': 'lng', 'y': 'lat', 0: var})
    )

    # Produce the H3 grid and populate it with the bathymetry statistics values.
    raster_mean = h3_raster_mean(raster_df, var, res, id)

    # If raster_means is None, assign the first DataFrame; otherwise, merge
    if raster_means is None:
        raster_means = raster_mean.copy()
    else:
        # Merge the DataFrame
        raster_means = pd.merge(raster_means, raster_mean, on=id, how='left')

raster_means.info()

# Merge the data layers to an out DF based on 'h3_id'
data_layers = pd.merge(raster_stats, raster_means, on=id, how='left')
data_layers.info()

##PRODUCE H3-GRID AND POPULATE GEOMETRY BASED ON H3-ID
# create empty DataFrame for storing H3-PARAMETERS
h3_parameters = pd.DataFrame([],columns=[
    'h3_id',
    'h3_geo_boundary',
    'h3_centroid',
    'h3_resolution'])

# populate parameters based on H3-ID
for h3_hex in data_layers[id]:
  h3_geo_boundary = shapely.geometry.Polygon(
      h3.h3_to_geo_boundary(h3_hex,geo_json=True))
  h3_centroid = Point(h3.h3_to_geo(h3_hex))
  h3_resolution = h3.h3_get_resolution(h3_hex)

  # Append results to dataframe
  h3_parameters.loc[len(h3_parameters)]=[
      h3_hex,
      h3_geo_boundary,
      h3_centroid,
      h3_resolution]

h3_parameters.info()

# Merge the data layers with the H3 parameters to an out DF based on 'h3_id'
h3_dataframe = pd.merge(h3_parameters, data_layers, on=id, how='left')

# this part is for naming the output with the current datetime and version
now = datetime.now()
now = now.strftime("%d%m"+"_"+"%H%M")

# Create a GeoDataFrame from your DataFrame
gdf_out = gpd.GeoDataFrame(h3_dataframe, geometry='h3_geo_boundary')

# Drop the 'h3_centroid' column
gdf_out['h3_centroid'] = gdf_out['h3_centroid'].apply(lambda point: point.wkt)

# Define the output GeoJSON file path
output_geojson_file = 'h3_' + zone + '_' + now + '.geojson'
print(output_geojson_file)

# Save the GeoDataFrame (without 'h3_centroid') to the new GeoJSON file
gdf_out.to_file(output_geojson_file, driver='GeoJSON')

# Plot the GeoJSON data
import matplotlib.pyplot as plt
gdf_out.plot()
plt.title(output_geojson_file)
plt.show()
